{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "d570eae4",
            "metadata": {},
            "source": [
                "# Side Information Experiment Notebook\n",
                "\n",
                "This notebook consolidates the original Python modules (`data_generation.py`, `models.py`, `experiment.py`, `visualization.py`) into sequential cells for easy execution (e.g. Google Colab).\n",
                "\n",
                "Sections:\n",
                "1. Imports & Utilities\n",
                "2. Data Generation (Distributions)\n",
                "3. Models (Vanilla & Strategic Classifiers)\n",
                "4. Experiment Orchestration (Parameter Sweep)\n",
                "5. Visualization (Correlation Space Plots)\n",
                "6. Demo Run (Small sweep)\n",
                "\n",
                "You can later expand the parameter sweep for full experiments."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "0e2beb3b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# --- 1. Imports & Global Utilities ---\n",
                "import numpy as np\n",
                "import pandas as pd\n",
                "import itertools\n",
                "import matplotlib.pyplot as plt\n",
                "from typing import Dict, Tuple, Any, List\n",
                "\n",
                "# Reproducibility helper (optional)\n",
                "def set_global_seed(seed: int = 0):\n",
                "    np.random.seed(seed)\n",
                "\n",
                "set_global_seed(0)\n",
                "print('Imports ready.')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "d5df2f3c",
            "metadata": {},
            "source": [
                "## 2. Data Generation\n",
                "Defines `BaseDistribution` and `PerturbedDistribution` producing samples (X, Y, Z, U).\n",
                "- (Y, Z, U) each in {-1, +1}.\n",
                "- `p` is visibility probability of Z (otherwise masked as NaN).\n",
                "- Correlations E[YZ], E[YU] can be perturbed by integer shift levels."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ff32e0a3",
            "metadata": {},
            "outputs": [],
            "source": [
                "class BaseDistribution:\n",
                "    COMBINATIONS = [\n",
                "        (-1, -1, -1), (-1, -1, 1), (-1, 1, -1), (-1, 1, 1),\n",
                "        (1, -1, -1), (1, -1, 1), (1, 1, -1), (1, 1, 1)\n",
                "    ]\n",
                "    def __init__(self, seed: int = 0):\n",
                "        self.rng = np.random.RandomState(seed)\n",
                "        raw = self.rng.rand(8)\n",
                "        self.pmf = raw / raw.sum()\n",
                "        self.mus = {}\n",
                "        self.sigmas = {}\n",
                "        for k in self.COMBINATIONS:\n",
                "            mu = self.rng.randn(2)\n",
                "            A = self.rng.randn(2, 2)\n",
                "            Sigma = A @ A.T + np.eye(2) * 0.1\n",
                "            self.mus[k] = mu\n",
                "            self.sigmas[k] = Sigma\n",
                "    def compute_corr(self):\n",
                "        corr_YZ = 0.0; corr_YU = 0.0\n",
                "        for prob, (y, z, u) in zip(self.pmf, self.COMBINATIONS):\n",
                "            corr_YZ += prob * y * z\n",
                "            corr_YU += prob * y * u\n",
                "        return float(corr_YZ), float(corr_YU)\n",
                "\n",
                "class PerturbedDistribution(BaseDistribution):\n",
                "    def __init__(self, perturb_level_YU=0, perturb_level_YZ=0, p: float = 1.0, seed: int = 10):\n",
                "        super().__init__(seed=seed)\n",
                "        self.p = float(p)\n",
                "        self.S_YU = int(perturb_level_YU)\n",
                "        self.S_YZ = int(perturb_level_YZ)\n",
                "        self.pmf = self._apply_perturbations(self.pmf)\n",
                "        self.corr_YZ, self.corr_YU = self.compute_corr()\n",
                "    def _joint_to_table(self, pmf):\n",
                "        return {k: float(p) for p, k in zip(pmf, BaseDistribution.COMBINATIONS)}\n",
                "    def _table_to_pmf(self, table):\n",
                "        arr = np.array([table[k] for k in BaseDistribution.COMBINATIONS], dtype=float)\n",
                "        arr = np.clip(arr, 0.0, None)\n",
                "        s = arr.sum()\n",
                "        if s <= 0: arr = np.ones_like(arr)/arr.size\n",
                "        else: arr = arr / s\n",
                "        return arr\n",
                "    def _apply_perturbations(self, pmf):\n",
                "        table = self._joint_to_table(pmf)\n",
                "        def _perturb_pair(table, A, B, S):\n",
                "            states = list(BaseDistribution.COMBINATIONS)\n",
                "            pAB = {}\n",
                "            vars = ['Y','Z','U']\n",
                "            for a in [-1,1]:\n",
                "                for b in [-1,1]:\n",
                "                    s_ = 0.0\n",
                "                    for (y,z,u) in states:\n",
                "                        vals={'Y':y,'Z':z,'U':u}\n",
                "                        if vals[A]==a and vals[B]==b: s_ += table[(y,z,u)]\n",
                "                    pAB[(a,b)] = s_\n",
                "            S_steps = abs(S); direction = 1 if S>=0 else -1\n",
                "            for _ in range(S_steps):\n",
                "                S_plus=[k for k in pAB if k[0]*k[1]==1]; S_minus=[k for k in pAB if k[0]*k[1]==-1]\n",
                "                P_plus=sum(pAB[k] for k in S_plus); P_minus=sum(pAB[k] for k in S_minus)\n",
                "                if (direction==1 and P_minus==0) or (direction==-1 and P_plus==0): break\n",
                "                t = (P_minus/3.0) if direction==1 else (P_plus/3.0)\n",
                "                if t<=0: break\n",
                "                src = S_minus if direction==1 else S_plus\n",
                "                dst = S_plus if direction==1 else S_minus\n",
                "                src_total=sum(pAB[k] for k in src)\n",
                "                if src_total<=0: break\n",
                "                for k in src:\n",
                "                    frac = pAB[k]/src_total if src_total>0 else 0\n",
                "                    delta = t*frac\n",
                "                    pAB[k] = max(pAB[k]-delta,0.0)\n",
                "                dst_total=sum(pAB[k] for k in dst)\n",
                "                if dst_total<=0:\n",
                "                    per = t/len(dst)\n",
                "                    for k in dst: pAB[k]+=per\n",
                "                else:\n",
                "                    for k in dst:\n",
                "                        frac=pAB[k]/dst_total\n",
                "                        pAB[k]+=t*frac\n",
                "            new_table={}\n",
                "            for (y,z,u) in states:\n",
                "                vals={'Y':y,'Z':z,'U':u}; a=vals[A]; b=vals[B]\n",
                "                p_ab_orig=0.0\n",
                "                for (yy,zz,uu) in states:\n",
                "                    v={'Y':yy,'Z':zz,'U':uu}\n",
                "                    if v[A]==a and v[B]==b: p_ab_orig += table[(yy,zz,uu)]\n",
                "                if p_ab_orig>0: p_c_given_ab = table[(y,z,u)]/p_ab_orig\n",
                "                else: p_c_given_ab = 0.5\n",
                "                new_table[(y,z,u)] = pAB[(a,b)] * p_c_given_ab\n",
                "            return new_table\n",
                "        table1 = _perturb_pair(table,'Y','U',self.S_YU)\n",
                "        table2 = _perturb_pair(table1,'Y','Z',self.S_YZ)\n",
                "        return self._table_to_pmf(table2)\n",
                "    def sample(self, n=100):\n",
                "        idx = self.rng.choice(8, size=n, p=self.pmf)\n",
                "        X = np.zeros((n,2)); Y=np.zeros(n,int); Z=np.zeros(n,float); U=np.zeros(n,int)\n",
                "        keys=list(self.COMBINATIONS)\n",
                "        for i,k in enumerate(keys):\n",
                "            mask = idx==i; cnt=mask.sum();\n",
                "            if cnt==0: continue\n",
                "            mu=self.mus[k]; Sigma=self.sigmas[k]\n",
                "            X[mask]=self.rng.multivariate_normal(mu,Sigma,size=cnt)\n",
                "            Y[mask]=k[0]; Z[mask]=k[1]; U[mask]=k[2]\n",
                "        vis = self.rng.rand(n) < self.p\n",
                "        Z_masked = np.where(vis, Z, np.nan)\n",
                "        return {\"X\":X, \"Y\":Y, \"Z\":Z_masked, \"U\":U}\n",
                "\n",
                "_dist_test = PerturbedDistribution(-1,2,p=0.5,seed=42)\n",
                "print('Sample corr (YZ,YU):', _dist_test.corr_YZ, _dist_test.corr_YU)"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "88477286",
            "metadata": {},
            "source": [
                "## 3. Models\n",
                "Defines `VanillaClassifier` and `StrategicClassifier` with numerically stable training."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "926bee4b",
            "metadata": {},
            "outputs": [],
            "source": [
                "def logistic_loss(y, s):\n",
                "    return np.logaddexp(0, -y * s)\n",
                "\n",
                "def _stable_sigmoid(x):\n",
                "    out = np.empty_like(x, dtype=float)\n",
                "    pos = x >= 0; out[pos] = 1.0 / (1.0 + np.exp(-x[pos]))\n",
                "    neg = ~pos; ex = np.exp(x[neg]); out[neg] = ex / (1.0 + ex)\n",
                "    return out\n",
                "\n",
                "def _clip_grad(grad, max_norm=5.0):\n",
                "    norm = np.linalg.norm(grad)\n",
                "    if norm > max_norm and norm > 0: return grad * (max_norm / norm)\n",
                "    return grad\n",
                "\n",
                "def sm_max(a,b,tau=5.0):\n",
                "    m=np.maximum(a,b)\n",
                "    return (np.log(np.exp(tau*(a-m))+np.exp(tau*(b-m))) + tau*m)/tau\n",
                "\n",
                "def sm_min(a,b,tau=5.0):\n",
                "    return -sm_max(-a,-b,tau)\n",
                "\n",
                "class BaseClassifier:\n",
                "    def __init__(self):\n",
                "        self.w_f=None; self.w_g=None; self.history={}\n",
                "    def _phi_f(self,X,Z):\n",
                "        n=X.shape[0]; Zf = np.where(np.isnan(Z),0.0,Z)\n",
                "        return np.column_stack([np.ones(n), X[:,0], X[:,1], Zf])\n",
                "    def _phi_g(self,X):\n",
                "        n=X.shape[0]; return np.column_stack([np.ones(n), X[:,0], X[:,1]])\n",
                "\n",
                "class VanillaClassifier(BaseClassifier):\n",
                "    def __init__(self, lr=1.0, epochs=200, weight_decay=1e-3):\n",
                "        super().__init__(); self.lr=lr; self.epochs=epochs; self.weight_decay=weight_decay\n",
                "    def fit(self,X,Y,Z,U=None):\n",
                "        n=X.shape[0]; Phi_f=self._phi_f(X,Z); Phi_g=self._phi_g(X)\n",
                "        self.w_f=np.zeros(Phi_f.shape[1]); self.w_g=np.zeros(Phi_g.shape[1]); self.history={'loss':None}\n",
                "        last=None\n",
                "        for ep in range(self.epochs):\n",
                "            mask_obs=~np.isnan(Z); s=np.zeros(n)\n",
                "            s[mask_obs]=Phi_f[mask_obs]@self.w_f; s[~mask_obs]=Phi_g[~mask_obs]@self.w_g\n",
                "            losses=logistic_loss(Y,s); loss=losses.mean()+0.5*self.weight_decay*(np.sum(self.w_f**2)+np.sum(self.w_g**2))\n",
                "            last=float(loss)\n",
                "            coeff=-Y*_stable_sigmoid(-Y*s)\n",
                "            grad_w_f=np.zeros_like(self.w_f); grad_w_g=np.zeros_like(self.w_g)\n",
                "            if mask_obs.any(): grad_w_f=(Phi_f[mask_obs].T @ coeff[mask_obs])/n + self.weight_decay*self.w_f\n",
                "            if (~mask_obs).any(): grad_w_g=(Phi_g[~mask_obs].T @ coeff[~mask_obs])/n + self.weight_decay*self.w_g\n",
                "            grad_w_f=_clip_grad(grad_w_f); grad_w_g=_clip_grad(grad_w_g)\n",
                "            self.w_f-=self.lr*grad_w_f; self.w_g-=self.lr*grad_w_g\n",
                "        self.history['loss']=last; return self\n",
                "    def eval(self,X,Y,Z,U=None):\n",
                "        n=X.shape[0]; Phi_f=self._phi_f(X,Z); Phi_g=self._phi_g(X)\n",
                "        mask_obs=~np.isnan(Z); s=np.zeros(n)\n",
                "        s[mask_obs]=Phi_f[mask_obs]@self.w_f; s[~mask_obs]=Phi_g[~mask_obs]@self.w_g\n",
                "        loss=logistic_loss(Y,s).mean(); preds=np.sign(s); acc=(preds==Y).mean()\n",
                "        return {'loss':float(loss),'accuracy':float(acc)}\n",
                "\n",
                "class StrategicClassifier(BaseClassifier):\n",
                "    def __init__(self, lr=1.0, epochs=200, tau=5.0, lam=1.0, weight_decay=1e-3):\n",
                "        super().__init__(); self.lr=lr; self.epochs=epochs; self.tau=tau; self.lam=lam; self.weight_decay=weight_decay\n",
                "    def fit(self,X,Y,Z,U):\n",
                "        n=X.shape[0]; Phi_f=self._phi_f(X,Z); Phi_g=self._phi_g(X)\n",
                "        self.w_f=np.zeros(Phi_f.shape[1]); self.w_g=np.zeros(Phi_g.shape[1]); self.history={'loss':None}\n",
                "        mask_obs=~np.isnan(Z); idx_vis=np.where(mask_obs)[0]; idx_hid=np.where(~mask_obs)[0]; last=None\n",
                "        for ep in range(self.epochs):\n",
                "            s_f=Phi_f@self.w_f; s_g=Phi_g@self.w_g; s=np.zeros(n); s[~mask_obs]=s_g[~mask_obs]\n",
                "            if mask_obs.any():\n",
                "                for i in idx_vis:\n",
                "                    if U[i]==1: s[i]=sm_max(s_f[i],s_g[i],tau=self.tau)\n",
                "                    else: s[i]=-sm_max(-s_f[i],-s_g[i],tau=self.tau)\n",
                "            losses=logistic_loss(Y,s)\n",
                "            reg=0.0\n",
                "            if mask_obs.any(): diff=s_f[mask_obs]-s_g[mask_obs]; reg=(diff**2).mean()\n",
                "            loss=losses.mean()+self.lam*reg+0.5*self.weight_decay*(np.sum(self.w_f**2)+np.sum(self.w_g**2))\n",
                "            last=float(loss)\n",
                "            coeff=-Y*_stable_sigmoid(-Y*s)\n",
                "            grad_w_f=np.zeros_like(self.w_f); grad_w_g=np.zeros_like(self.w_g)\n",
                "            if len(idx_hid)>0: grad_w_g+=(Phi_g[idx_hid].T @ coeff[idx_hid])/n\n",
                "            for i in idx_vis:\n",
                "                sf=s_f[i]; sg=s_g[i]\n",
                "                if U[i]==1:\n",
                "                    a=self.tau*sf; b=self.tau*sg; m=max(a,b); wa=np.exp(a-m); wb=np.exp(b-m); denom=wa+wb; dsf=wa/denom; dsg=wb/denom\n",
                "                else:\n",
                "                    a=-self.tau*sf; b=-self.tau*sg; m=max(a,b); wa=np.exp(a-m); wb=np.exp(b-m); denom=wa+wb; dsf=-(wa/denom); dsg=-(wb/denom)\n",
                "                grad_w_f += (Phi_f[i]*(coeff[i]*dsf))/n + (2.0/n)*self.lam*(sf-sg)*Phi_f[i]\n",
                "                grad_w_g += (Phi_g[i]*(coeff[i]*dsg))/n + (-2.0/n)*self.lam*(sf-sg)*Phi_g[i]\n",
                "            grad_w_f=_clip_grad(grad_w_f); grad_w_g=_clip_grad(grad_w_g)\n",
                "            self.w_f-=self.lr*grad_w_f; self.w_g-=self.lr*grad_w_g\n",
                "        self.history['loss']=last; return self\n",
                "    def eval(self,X,Y,Z,U):\n",
                "        n=X.shape[0]; Phi_f=self._phi_f(X,Z); Phi_g=self._phi_g(X)\n",
                "        s_f=Phi_f@self.w_f; s_g=Phi_g@self.w_g; s=np.zeros(n); mask_obs=~np.isnan(Z)\n",
                "        idx_vis=np.where(mask_obs)[0]; idx_hid=np.where(~mask_obs)[0]\n",
                "        for i in idx_vis:\n",
                "            if U[i]==1: s[i]=max(s_f[i],s_g[i])\n",
                "            else: s[i]=min(s_f[i],s_g[i])\n",
                "        if len(idx_hid)>0: s[idx_hid]=s_g[idx_hid]\n",
                "        loss=logistic_loss(Y,s).mean(); preds=np.sign(s); acc=(preds==Y).mean()\n",
                "        return {'loss':float(loss),'accuracy':float(acc)}\n",
                "\n",
                "print('Models ready.')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "8944ed75",
            "metadata": {},
            "source": [
                "## 4. Experiment Orchestration\n",
                "`Experiment` class runs parameter sweeps and aggregates results."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "ed5dfbbe",
            "metadata": {},
            "outputs": [],
            "source": [
                "class Experiment:\n",
                "    def __init__(self, param_space: Dict[str, list], seed=0):\n",
                "        self.param_space = param_space; self.seed=seed; self.results: List[Dict[str, Any]] = []\n",
                "    def single_run(self, params: Dict[str, Any], model_hparams=None):\n",
                "        dist = PerturbedDistribution(\n",
                "            perturb_level_YU=params['perturb_level_YU'],\n",
                "            perturb_level_YZ=params['perturb_level_YZ'],\n",
                "            p=params['p'], seed=self.seed)\n",
                "        train_n = params.get('train_n', 1000); test_n = params.get('test_n', 1000)\n",
                "        train = dist.sample(train_n); test = dist.sample(test_n)\n",
                "        if model_hparams is None: model_hparams = {}\n",
                "        van = VanillaClassifier(**model_hparams.get('vanilla', {}))\n",
                "        strat = StrategicClassifier(**model_hparams.get('strategic', {}))\n",
                "        van.fit(train['X'], train['Y'], train['Z'], train['U']); strat.fit(train['X'], train['Y'], train['Z'], train['U'])\n",
                "        van_train = van.eval(train['X'], train['Y'], train['Z'], train['U']); van_test = van.eval(test['X'], test['Y'], test['Z'], test['U'])\n",
                "        strat_train = strat.eval(train['X'], train['Y'], train['Z'], train['U']); strat_test = strat.eval(test['X'], test['Y'], test['Z'], test['U'])\n",
                "        res = {**params, 'corr_YU': dist.corr_YU, 'corr_YZ': dist.corr_YZ,\n",
                "               'van_w_f': van.w_f.tolist(), 'van_w_g': van.w_g.tolist(),\n",
                "               'strat_w_f': strat.w_f.tolist(), 'strat_w_g': strat.w_g.tolist(),\n",
                "               'van_train_loss': van_train['loss'], 'van_test_loss': van_test['loss'], 'van_test_acc': van_test['accuracy'],\n",
                "               'strat_train_loss': strat_train['loss'], 'strat_test_loss': strat_test['loss'], 'strat_test_acc': strat_test['accuracy']}\n",
                "        self.results.append(res); return res\n",
                "    def run_sweep(self, model_hparams=None):\n",
                "        keys=list(self.param_space.keys()); values=[self.param_space[k] for k in keys]\n",
                "        combos=list(itertools.product(*values)); total=len(combos); results=[]\n",
                "        for idx, combo in enumerate(combos,1):\n",
                "            print(f'Sweep {idx}/{total} ({idx/total:.1%})', end='\\r')\n",
                "            params=dict(zip(keys, combo)); res=self.single_run(params, model_hparams=model_hparams); results.append(res)\n",
                "        print(); return results\n",
                "    def get_results_df(self):\n",
                "        return pd.DataFrame(self.results)\n",
                "    def save_csv(self, path='experiment_results.csv'):\n",
                "        df=self.get_results_df(); col_order=[]\n",
                "        if 'p' in df.columns: col_order.append('p')\n",
                "        for c in ['corr_YZ','corr_YU']:\n",
                "            if c in df.columns: col_order.append(c)\n",
                "        param_cols=[c for c in ['perturb_level_YU','perturb_level_YZ','train_n','test_n'] if c in df.columns]\n",
                "        col_order.extend(param_cols)\n",
                "        rest=[c for c in df.columns if c not in col_order]\n",
                "        col_order.extend(rest); df=df[col_order]\n",
                "        sort_keys=[k for k in ['p','corr_YZ','corr_YU','perturb_level_YU','perturb_level_YZ','train_n','test_n'] if k in df.columns]\n",
                "        df=df.sort_values(by=sort_keys).reset_index(drop=True)\n",
                "        df.to_csv(path, index=False); return path\n",
                "print('Experiment class ready.')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "60948e0a",
            "metadata": {},
            "source": [
                "## 5. Visualization\n",
                "Plots which model wins (Vanilla vs Strategic) across correlation space, per `p`."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "e8267708",
            "metadata": {},
            "outputs": [],
            "source": [
                "def plot_correlation_space(csv_path='experiment_results.csv'):\n",
                "    results = pd.read_csv(csv_path)\n",
                "    p_values = sorted(results['p'].unique())\n",
                "    color_map = {0:'tab:blue', 1:'tab:orange', 2:'gray'}\n",
                "    label_map = {0:'Vanilla', 1:'Strategic', 2:'Tie'}\n",
                "    for metric, label, vcol, scol in [\n",
                "        ('test_loss','Model with Lower Test Loss','van_test_loss','strat_test_loss'),\n",
                "        ('test_acc','Model with Higher Test Accuracy','van_test_acc','strat_test_acc')]:\n",
                "        for p in p_values:\n",
                "            dfp = results[results['p']==p]\n",
                "            if len(dfp)==0: continue\n",
                "            if metric=='test_loss':\n",
                "                margin = (dfp[scol]-dfp[vcol]) / np.maximum(dfp[vcol], dfp[scol])\n",
                "                winner = np.where(margin>0.05,0,np.where(margin<-0.05,1,2))\n",
                "            else:\n",
                "                margin = (dfp[vcol]-dfp[scol]) / np.maximum(dfp[vcol], dfp[scol])\n",
                "                winner = np.where(margin>0.05,0,np.where(margin<-0.05,1,2))\n",
                "            colors=[color_map[w] for w in winner]\n",
                "            plt.figure(figsize=(6.5,5.5))\n",
                "            plt.scatter(dfp['corr_YZ'], dfp['corr_YU'], c=colors, alpha=0.85, edgecolor='k')\n",
                "            for i in [0,1,2]: plt.scatter([],[],c=color_map[i],label=label_map[i])\n",
                "            plt.xlabel('Correlation E[YZ]'); plt.ylabel('Correlation E[YU]')\n",
                "            plt.title(f'{label} (p={p})')\n",
                "            plt.legend(title='Winner'); plt.grid(True,linestyle='--',alpha=0.5)\n",
                "            plt.tight_layout(); plt.savefig(f'correlation_space_{metric}_p{p}.png'); plt.close()\n",
                "print('Visualization helper ready.')"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "20f93527",
            "metadata": {},
            "source": [
                "## 6. Demo Run\n",
                "Runs a SMALL sweep for speed. You can expand later (see commented example)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "4a05582b",
            "metadata": {},
            "outputs": [],
            "source": [
                "# Small demo parameter space (adjust as needed).\n",
                "demo_param_space = {\n",
                "    'perturb_level_YU': [-1,0,1],\n",
                "    'perturb_level_YZ': [-1,0,1],\n",
                "    'p': [0.0, 0.5, 1.0],\n",
                "    'train_n': [800],\n",
                "    'test_n': [300]\n",
                "}\n",
                "exp = Experiment(demo_param_space, seed=50)\n",
                "_ = exp.run_sweep()\n",
                "csv_path = exp.save_csv('experiment_results_demo.csv')\n",
                "print('Demo sweep completed. Rows:', len(exp.results))\n",
                "try:\n",
                "    from IPython.display import display\n",
                "    display(exp.get_results_df().head())\n",
                "except Exception:\n",
                "    print(exp.get_results_df().head())\n",
                "plot_correlation_space(csv_path)\n",
                "print('Plots saved for demo (test_loss & test_acc variants).')\n",
                "\n",
                "# For FULL sweep (longer runtime) uncomment and adjust:\n",
                "# full_param_space = {\n",
                "#     'perturb_level_YU': [-3,-2,-1,0,1,2,3],\n",
                "#     'perturb_level_YZ': [-3,-2,-1,0,1,2,3],\n",
                "#     'p': [0,0.25,0.5,0.75,1],\n",
                "#     'train_n': [2500],\n",
                "#     'test_n': [500]\n",
                "# }\n",
                "# exp_full = Experiment(full_param_space, seed=50)\n",
                "# exp_full.run_sweep()\n",
                "# exp_full.save_csv('experiment_results_full.csv')\n",
                "# plot_correlation_space('experiment_results_full.csv')\n",
                "# print('Full sweep complete.')"
            ]
        }
    ],
    "metadata": {
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
